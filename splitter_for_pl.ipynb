{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 bed, 23.4ms\n",
      "Speed: 1.0ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 21.0ms\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 22.1ms\n",
      "Speed: 1.0ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 24.4ms\n",
      "Speed: 1.0ms preprocess, 24.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 23.3ms\n",
      "Speed: 0.9ms preprocess, 23.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 24.2ms\n",
      "Speed: 0.7ms preprocess, 24.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 23.0ms\n",
      "Speed: 1.2ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 24.0ms\n",
      "Speed: 0.9ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.0ms\n",
      "Speed: 0.9ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 22.6ms\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 25.5ms\n",
      "Speed: 1.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 22.1ms\n",
      "Speed: 1.0ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 20.4ms\n",
      "Speed: 1.0ms preprocess, 20.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 23.3ms\n",
      "Speed: 1.0ms preprocess, 23.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.4ms\n",
      "Speed: 1.0ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 1 sink, 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.9ms\n",
      "Speed: 1.1ms preprocess, 23.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 24.1ms\n",
      "Speed: 0.8ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.4ms\n",
      "Speed: 1.0ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 22.6ms\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.2ms\n",
      "Speed: 1.0ms preprocess, 23.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 21.3ms\n",
      "Speed: 1.0ms preprocess, 21.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.7ms\n",
      "Speed: 1.3ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 23.1ms\n",
      "Speed: 1.1ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 23.8ms\n",
      "Speed: 0.9ms preprocess, 23.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 22.3ms\n",
      "Speed: 1.0ms preprocess, 22.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 24.3ms\n",
      "Speed: 1.0ms preprocess, 24.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 1 sink, 24.6ms\n",
      "Speed: 1.0ms preprocess, 24.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 24.1ms\n",
      "Speed: 1.0ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 1 sink, 23.7ms\n",
      "Speed: 1.0ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 1 sink, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.4ms\n",
      "Speed: 1.0ms preprocess, 23.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 24.7ms\n",
      "Speed: 1.0ms preprocess, 24.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 1 sink, 24.5ms\n",
      "Speed: 0.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 22.1ms\n",
      "Speed: 0.7ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 23.0ms\n",
      "Speed: 0.8ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 21.4ms\n",
      "Speed: 1.0ms preprocess, 21.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 19.7ms\n",
      "Speed: 1.0ms preprocess, 19.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 20.7ms\n",
      "Speed: 1.0ms preprocess, 20.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 22.5ms\n",
      "Speed: 0.6ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 1 sink, 23.7ms\n",
      "Speed: 1.3ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "[INFO] Interrupted by user.\n",
      "[INFO] Exiting...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from collections import deque\n",
    "import os\n",
    "import shutil\n",
    "import threading\n",
    "import queue\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "@dataclass\n",
    "class VideoWriterState:\n",
    "    writer: cv2.VideoWriter\n",
    "    frame_queue: queue.Queue\n",
    "    active: bool = True\n",
    "\n",
    "class ThreadedVideoWriter:\n",
    "    def __init__(self, path: str, fourcc: int, fps: float, frame_size: tuple):\n",
    "        self.writer = cv2.VideoWriter(path, fourcc, fps, frame_size)\n",
    "        self.frame_queue = queue.Queue(maxsize=300)  # Buffer size of 300 frames\n",
    "        self.active = True\n",
    "        self.thread = threading.Thread(target=self._write_frames)\n",
    "        self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "        self.frames_written = 0\n",
    "\n",
    "    def _write_frames(self):\n",
    "        while self.active or not self.frame_queue.empty():\n",
    "            try:\n",
    "                frame = self.frame_queue.get(timeout=1.0)\n",
    "                self.writer.write(frame)\n",
    "                self.frames_written += 1\n",
    "                self.frame_queue.task_done()\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error writing frame: {e}\")\n",
    "\n",
    "    def write(self, frame):\n",
    "        if self.active:\n",
    "            try:\n",
    "                self.frame_queue.put(frame.copy(), timeout=1.0)\n",
    "            except queue.Full:\n",
    "                print(\"[WARNING] Frame queue full, dropping frame\")\n",
    "\n",
    "    def release(self):\n",
    "        self.active = False\n",
    "        self.thread.join()\n",
    "        self.writer.release()\n",
    "        return self.frames_written > 0  # Return True if any frames were written\n",
    "\n",
    "def live_yolo_video_splitter(\n",
    "    output_dir=\"output_videos\",\n",
    "    yolo_model_path=\"yolov8n.pt\",\n",
    "    confidence_threshold=0.5,\n",
    "    buffer_size=60,\n",
    "    max_frames_no_person_after=60,\n",
    "    fps=30,\n",
    "    consecutive_frames_needed=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Live monitoring of webcam to split into videos when a person is detected.\n",
    "    Uses multithreading for video writing to prevent frame drops.\n",
    "    \"\"\"\n",
    "    # Create directory structure\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    before_dir = os.path.join(output_dir, \"before_no_person\")\n",
    "    after_dir = os.path.join(output_dir, \"after_no_person\")\n",
    "    person_dir = os.path.join(output_dir, \"person\")\n",
    "    no_person_dir = os.path.join(output_dir, \"no_person\")\n",
    "    temp_dir = os.path.join(output_dir, \"temp\")\n",
    "    \n",
    "    for dir_path in [before_dir, after_dir, person_dir, no_person_dir, temp_dir]:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    # Initialize YOLO\n",
    "    model = YOLO(yolo_model_path)\n",
    "\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    # Get frame dimensions\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_size = (width, height)\n",
    "\n",
    "    # Test and set video codec\n",
    "    try:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'avc1')  # H264 codec\n",
    "        test_path = os.path.join(temp_dir, 'test.mp4')\n",
    "        test_writer = cv2.VideoWriter(test_path, fourcc, fps, frame_size)\n",
    "        test_writer.release()\n",
    "        os.remove(test_path)\n",
    "    except:\n",
    "        print(\"[WARNING] H264 codec not available, falling back to mp4v\")\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "    # Initialize state\n",
    "    buffer_frames = deque(maxlen=buffer_size)\n",
    "    person_in_frame = False\n",
    "    consecutive_person_frames = 0\n",
    "    consecutive_noperson_frames = 0\n",
    "    video_id = 1\n",
    "    no_person_after_count = 0\n",
    "    writers: Dict[str, Optional[ThreadedVideoWriter]] = {\n",
    "        'before': None,\n",
    "        'person': None,\n",
    "        'after': None,\n",
    "        'no_person': None\n",
    "    }\n",
    "    temp_files = {\n",
    "        'before': None,\n",
    "        'person': None,\n",
    "        'after': None,\n",
    "        'no_person': None\n",
    "    }\n",
    "\n",
    "    def get_temp_paths(vid_id):\n",
    "        return {\n",
    "            'before': os.path.join(temp_dir, f\"before_no_person_{vid_id}.mp4\"),\n",
    "            'person': os.path.join(temp_dir, f\"person_{vid_id}.mp4\"),\n",
    "            'after': os.path.join(temp_dir, f\"after_no_person_{vid_id}.mp4\"),\n",
    "            'no_person': os.path.join(temp_dir, f\"no_person_{vid_id}.mp4\")\n",
    "        }\n",
    "\n",
    "    def get_final_paths(vid_id):\n",
    "        return {\n",
    "            'before': os.path.join(before_dir, f\"before_no_person_{vid_id}.mp4\"),\n",
    "            'person': os.path.join(person_dir, f\"person_{vid_id}.mp4\"),\n",
    "            'after': os.path.join(after_dir, f\"after_no_person_{vid_id}.mp4\"),\n",
    "            'no_person': os.path.join(no_person_dir, f\"no_person_{vid_id}.mp4\")\n",
    "        }\n",
    "\n",
    "    def close_and_move_recordings(current_video_id):\n",
    "        nonlocal writers, temp_files\n",
    "        \n",
    "        # Close all writers and wait for threads to finish\n",
    "        valid_files = {}\n",
    "        for key, writer in writers.items():\n",
    "            if writer is not None:\n",
    "                frames_written = writer.release()\n",
    "                if frames_written:\n",
    "                    valid_files[key] = temp_files[key]\n",
    "\n",
    "        # Move valid files to final location\n",
    "        final_paths = get_final_paths(current_video_id)\n",
    "        for key, temp_path in valid_files.items():\n",
    "            if os.path.exists(temp_path):\n",
    "                try:\n",
    "                    # Verify file is valid\n",
    "                    cap = cv2.VideoCapture(temp_path)\n",
    "                    if cap.isOpened():\n",
    "                        cap.release()\n",
    "                        shutil.move(temp_path, final_paths[key])\n",
    "                        print(f\"[INFO] Moved {os.path.basename(temp_path)} to final location\")\n",
    "                    else:\n",
    "                        print(f\"[WARNING] Corrupted file detected: {temp_path}\")\n",
    "                        os.remove(temp_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed to move {temp_path}: {e}\")\n",
    "\n",
    "        writers = {key: None for key in writers}\n",
    "        temp_files = {key: None for key in temp_files}\n",
    "\n",
    "    def start_new_recordings():\n",
    "        nonlocal writers, temp_files, video_id\n",
    "        \n",
    "        # Close and move previous recordings\n",
    "        if any(writers.values()):\n",
    "            close_and_move_recordings(video_id - 1)\n",
    "            time.sleep(0.1)  # Small delay to ensure files are closed\n",
    "\n",
    "        # Initialize new temp paths\n",
    "        temp_files = get_temp_paths(video_id)\n",
    "        \n",
    "        # Create new writers\n",
    "        writers = {\n",
    "            'before': ThreadedVideoWriter(temp_files['before'], fourcc, fps, frame_size),\n",
    "            'person': ThreadedVideoWriter(temp_files['person'], fourcc, fps, frame_size),\n",
    "            'after': ThreadedVideoWriter(temp_files['after'], fourcc, fps, frame_size),\n",
    "            'no_person': ThreadedVideoWriter(temp_files['no_person'], fourcc, fps, frame_size)\n",
    "        }\n",
    "\n",
    "        print(f\"[INFO] Starting new recordings (ID: {video_id})\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"[INFO] Cannot read from camera or end of stream.\")\n",
    "                break\n",
    "\n",
    "            # Store a copy of the frame in the buffer\n",
    "            buffer_frames.append(frame.copy())\n",
    "            \n",
    "            # Process frame with YOLO\n",
    "            results = model(frame, conf=confidence_threshold)\n",
    "            has_person = any(int(box.cls[0]) == 0 for box in results[0].boxes)\n",
    "\n",
    "            if has_person:\n",
    "                consecutive_person_frames += 1\n",
    "                consecutive_noperson_frames = 0\n",
    "            else:\n",
    "                consecutive_noperson_frames += 1\n",
    "                consecutive_person_frames = 0\n",
    "\n",
    "            # Handle transition to person detected\n",
    "            if not person_in_frame and consecutive_person_frames >= consecutive_frames_needed:\n",
    "                person_in_frame = True\n",
    "                no_person_after_count = 0\n",
    "                start_new_recordings()\n",
    "                \n",
    "                # Write buffer to before_no_person and no_person\n",
    "                if writers['before'] and writers['no_person']:\n",
    "                    for bf in buffer_frames:\n",
    "                        writers['before'].write(bf)\n",
    "                        writers['no_person'].write(bf)\n",
    "\n",
    "            # Handle transition to no person\n",
    "            elif person_in_frame and consecutive_noperson_frames >= consecutive_frames_needed:\n",
    "                person_in_frame = False\n",
    "                no_person_after_count = 0\n",
    "\n",
    "            # Write current frame\n",
    "            if person_in_frame:\n",
    "                if writers['person']:\n",
    "                    writers['person'].write(frame)\n",
    "            else:\n",
    "                if any(writers.values()):\n",
    "                    no_person_after_count += 1\n",
    "                    if writers['after']:\n",
    "                        writers['after'].write(frame)\n",
    "                    if writers['no_person']:\n",
    "                        writers['no_person'].write(frame)\n",
    "                    \n",
    "                    if no_person_after_count >= max_frames_no_person_after:\n",
    "                        close_and_move_recordings(video_id)\n",
    "                        video_id += 1\n",
    "\n",
    "            cv2.imshow(\"Live Feed\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"[INFO] Interrupted by user.\")\n",
    "    finally:\n",
    "        # Cleanup\n",
    "        if any(writers.values()):\n",
    "            close_and_move_recordings(video_id)\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        if os.path.exists(temp_dir):\n",
    "            shutil.rmtree(temp_dir)\n",
    "        print(\"[INFO] Exiting...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    live_yolo_video_splitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 bottle, 1 bed, 25.5ms\n",
      "Speed: 0.6ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 22.4ms\n",
      "Speed: 1.0ms preprocess, 22.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 1 sink, 23.8ms\n",
      "Speed: 1.0ms preprocess, 23.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.0ms\n",
      "Speed: 1.2ms preprocess, 23.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.0ms\n",
      "Speed: 1.1ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 1 bed, 1 sink, 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bed, 23.2ms\n",
      "Speed: 1.0ms preprocess, 23.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "[INFO] Interrupted by user.\n",
      "[INFO] Exiting...\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "#slimmed down works well\n",
    "\n",
    "import cv2\n",
    "from collections import deque\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Import the YOLO class from ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def live_yolo_video_splitter(\n",
    "    output_dir=\"output_videos\",\n",
    "    yolo_model_path=\"yolov8n.pt\",\n",
    "    confidence_threshold=0.5,\n",
    "    buffer_size=60,\n",
    "    max_frames_no_person_after=60,\n",
    "    fps=30,\n",
    "    consecutive_frames_needed=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Live monitoring of webcam to split into two videos whenever a person is detected.\n",
    "    Videos are written to a temporary directory and only moved to final location\n",
    "    when the next recording starts.\n",
    "    \"\"\"\n",
    "    # Create the output and temp directories\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    temp_dir = os.path.join(output_dir, \"temp\")\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize the YOLOv8 model\n",
    "    model = YOLO(yolo_model_path)\n",
    "\n",
    "    # Initialize webcam capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    # Get frame dimensions\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Use H264 codec if available, fallback to mp4v if not\n",
    "    try:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'avc1')  # H264 codec\n",
    "        test_writer = cv2.VideoWriter(\n",
    "            os.path.join(temp_dir, 'test.mp4'),\n",
    "            fourcc, fps, (width, height)\n",
    "        )\n",
    "        test_writer.release()\n",
    "        os.remove(os.path.join(temp_dir, 'test.mp4'))\n",
    "    except:\n",
    "        print(\"[WARNING] H264 codec not available, falling back to mp4v\")\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "    # Rolling buffer for the last `buffer_size` frames\n",
    "    buffer_frames = deque(maxlen=buffer_size)\n",
    "\n",
    "    # State variables\n",
    "    person_in_frame = False\n",
    "    consecutive_person_frames = 0\n",
    "    consecutive_noperson_frames = 0\n",
    "\n",
    "    # Video control\n",
    "    video_id = 1\n",
    "    out_no_person = None\n",
    "    out_person = None\n",
    "    recording_person = False\n",
    "    recording_no_person = False\n",
    "    no_person_after_count = 0\n",
    "    previous_temp_files = []  # Track previous recording's files\n",
    "\n",
    "    def start_new_recordings():\n",
    "        nonlocal out_no_person, out_person, video_id, recording_person, recording_no_person, previous_temp_files\n",
    "        \n",
    "        # Move previous recordings to final location if they exist\n",
    "        for temp_path in previous_temp_files:\n",
    "            if os.path.exists(temp_path):\n",
    "                final_path = os.path.join(output_dir, os.path.basename(temp_path))\n",
    "                shutil.move(temp_path, final_path)\n",
    "                print(f\"[INFO] Moved {os.path.basename(temp_path)} to final location\")\n",
    "        \n",
    "        # Start new recordings\n",
    "        temp_no_person = os.path.join(temp_dir, f\"no_person_{video_id}.mp4\")\n",
    "        temp_person = os.path.join(temp_dir, f\"person_{video_id}.mp4\")\n",
    "        \n",
    "        out_no_person = cv2.VideoWriter(temp_no_person, fourcc, fps, (width, height))\n",
    "        out_person = cv2.VideoWriter(temp_person, fourcc, fps, (width, height))\n",
    "\n",
    "        recording_no_person = True\n",
    "        recording_person = True\n",
    "        \n",
    "        # Store current paths as previous for next cycle\n",
    "        previous_temp_files = [temp_no_person, temp_person]\n",
    "\n",
    "        print(f\"[INFO] Starting new recordings (ID: {video_id})\")\n",
    "\n",
    "    def close_recordings():\n",
    "        nonlocal out_no_person, out_person, recording_person, recording_no_person\n",
    "        if out_no_person is not None:\n",
    "            out_no_person.release()\n",
    "            out_no_person = None\n",
    "        if out_person is not None:\n",
    "            out_person.release()\n",
    "            out_person = None\n",
    "\n",
    "        recording_person = False\n",
    "        recording_no_person = False\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"[INFO] Cannot read from camera or end of stream.\")\n",
    "                break\n",
    "\n",
    "            # Rest of the main loop remains exactly the same\n",
    "            buffer_frames.append(frame)\n",
    "            results = model(frame, conf=confidence_threshold)\n",
    "            yolo_boxes = results[0].boxes\n",
    "            has_person = any(int(box.cls[0]) == 0 for box in yolo_boxes)\n",
    "\n",
    "            if has_person:\n",
    "                consecutive_person_frames += 1\n",
    "                consecutive_noperson_frames = 0\n",
    "            else:\n",
    "                consecutive_noperson_frames += 1\n",
    "                consecutive_person_frames = 0\n",
    "\n",
    "            if not person_in_frame:\n",
    "                if consecutive_person_frames >= consecutive_frames_needed:\n",
    "                    person_in_frame = True\n",
    "                    no_person_after_count = 0\n",
    "                    start_new_recordings()\n",
    "                    if out_no_person:\n",
    "                        for bf in buffer_frames:\n",
    "                            out_no_person.write(bf)\n",
    "            else:\n",
    "                if consecutive_noperson_frames >= consecutive_frames_needed:\n",
    "                    person_in_frame = False\n",
    "                    no_person_after_count = 0\n",
    "\n",
    "            if person_in_frame:\n",
    "                if recording_person and out_person:\n",
    "                    out_person.write(frame)\n",
    "            else:\n",
    "                if recording_person:\n",
    "                    no_person_after_count += 1\n",
    "                    if recording_no_person and out_no_person:\n",
    "                        out_no_person.write(frame)\n",
    "\n",
    "                    if no_person_after_count >= max_frames_no_person_after:\n",
    "                        close_recordings()\n",
    "                        video_id += 1\n",
    "\n",
    "            cv2.imshow(\"Live Feed\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"[INFO] Interrupted by user.\")\n",
    "    finally:\n",
    "        # Close current recordings\n",
    "        close_recordings()\n",
    "        \n",
    "        # Move the last set of recordings to final location\n",
    "        for temp_path in previous_temp_files:\n",
    "            if os.path.exists(temp_path):\n",
    "                final_path = os.path.join(output_dir, os.path.basename(temp_path))\n",
    "                shutil.move(temp_path, final_path)\n",
    "                print(f\"[INFO] Moved final {os.path.basename(temp_path)} to final location\")\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        # Clean up temp directory\n",
    "        if os.path.exists(temp_dir):\n",
    "            shutil.rmtree(temp_dir)\n",
    "        print(\"[INFO] Exiting...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    live_yolo_video_splitter()\n",
    "    print('hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
